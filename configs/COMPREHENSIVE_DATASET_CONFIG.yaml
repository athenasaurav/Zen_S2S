# COMPREHENSIVE VITA-Audio Dataset Configuration
# Based on original sts_finetune_stage1.yaml structure
# Includes your custom data with proper ratios

xlsx_sample_num: 5

dataset:
  # ========================================
  # YOUR CUSTOM DATA (Primary Training Data)
  # ========================================
  
  # Your ASR data - Automatic Speech Recognition
  custom_asr:
    ratio: 2.0  # Higher ratio for your custom ASR data
    data_paths:
      - /workspace/VITA-Audio/clear_data/ASR/ASR.jsonl

  # Your TTS data - Text-to-Speech
  custom_tts:
    ratio: 2.0  # Higher ratio for your custom TTS data
    data_paths:
      - /workspace/VITA-Audio/clear_data/TTS/TTS.jsonl

  # Your Speech QnA data - Speech Question & Answer
  custom_speech_qna:
    ratio: 3.0  # Highest ratio for your main training data
    data_paths:
      - /workspace/VITA-Audio/clear_data/speech_qna/speechqna.jsonl

  # ========================================
  # STANDARD DATASETS (If Available)
  # ========================================
  # Note: These are from the original config but may not be available
  # Comment out sections for datasets you don't have
  
  # WenetSpeech datasets (if you have them)
  # wenet-e2e/wenetspeech:
  #   ratio: 1.0
  #   data_paths:
  #     - datasets/jsonl/wenet-e2e/wenetspeech/L_fixed.jsonl
  #     - datasets/jsonl/wenet-e2e/wenetspeech/DEV_fixed.jsonl

  # WenetSpeech4TTS datasets (if you have them)
  # WenetSpeech4TTS/WenetSpeech4TTS:
  #   ratio: 1.0
  #   data_paths:
  #     - datasets/jsonl/WenetSpeech4TTS/WenetSpeechTTS/Basic.jsonl

  # LibriSpeech datasets (if you have them)
  # fixie-ai/librispeech_asr:
  #   ratio: 1.0
  #   data_paths:
  #     - datasets/jsonl/fixie-ai/librispeech_asr/train.100.clean.jsonl
  #     - datasets/jsonl/fixie-ai/librispeech_asr/train.360.clean.jsonl
  #     - datasets/jsonl/fixie-ai/librispeech_asr/train.500.other.jsonl

  # MythicInfinity datasets (if you have them)
  # mythicinifinity/libriTTS:
  #   ratio: 1.0
  #   data_paths:
  #     - datasets/jsonl/mythicinifinity/libriTTS/train.clean.100.jsonl
  #     - datasets/jsonl/mythicinifinity/libriTTS/train.clean.360.jsonl
  #     - datasets/jsonl/mythicinifinity/libriTTS/train.other.500.jsonl

  # Parler-TTS datasets (if you have them)
  # parler-tts/mls_eng:
  #   ratio: 1.0
  #   data_paths:
  #     - datasets/jsonl/parler-tts/mls_eng_10k/train.jsonl

  # Mozilla Common Voice (if you have them)
  # mozilla-foundation/common_voice_17_0:
  #   ratio: 1.0
  #   data_paths:
  #     - datasets/jsonl/mozilla-foundation/common_voice_17_0/en/train.jsonl
  #     - datasets/jsonl/mozilla-foundation/common_voice_17_0/zh-CN/train.jsonl

  # Mushan GLOBE datasets (if you have them)
  # Mushan/GLOBE_V2:
  #   ratio: 1.0
  #   data_paths:
  #     - datasets/jsonl/Mushan/GLOBE_V2/train.jsonl

  # Amphion Emilia datasets (if you have them)
  # amphion/Emilia-Dataset:
  #   ratio: 0.5
  #   data_paths:
  #     - datasets/jsonl/amphion/Emilia-Dataset/ZH_B000000_B000100.jsonl
  #     - datasets/jsonl/amphion/Emilia-Dataset/ZH_B000100_B000200.jsonl
  #     - datasets/jsonl/amphion/Emilia-Dataset/ZH_B000200_B000300.jsonl
  #     - datasets/jsonl/amphion/Emilia-Dataset/ZH_B000300_B000400.jsonl
  #     - datasets/jsonl/amphion/Emilia-Dataset/ZH_B000400_B000500.jsonl
  #     - datasets/jsonl/amphion/Emilia-Dataset/ZH_B000500_B000600.jsonl
  #     - datasets/jsonl/amphion/Emilia-Dataset/ZH_B000600_B000700.jsonl
  #     - datasets/jsonl/amphion/Emilia-Dataset/ZH_B000700_B000800.jsonl
  #     - datasets/jsonl/amphion/Emilia-Dataset/ZH_B000800_B000900.jsonl
  #     - datasets/jsonl/amphion/Emilia-Dataset/ZH_B000900_B001000.jsonl
  #     - datasets/jsonl/amphion/Emilia-Dataset/EN_B000000_B000100.jsonl
  #     - datasets/jsonl/amphion/Emilia-Dataset/EN_B000100_B000200.jsonl
  #     - datasets/jsonl/amphion/Emilia-Dataset/EN_B000200_B000300.jsonl
  #     - datasets/jsonl/amphion/Emilia-Dataset/EN_B000300_B000400.jsonl
  #     - datasets/jsonl/amphion/Emilia-Dataset/EN_B000400_B000500.jsonl
  #     - datasets/jsonl/amphion/Emilia-Dataset/EN_B000500_B000600.jsonl
  #     - datasets/jsonl/amphion/Emilia-Dataset/EN_B000600_B000700.jsonl

# ========================================
# CONFIGURATION NOTES
# ========================================
# 
# Ratios Explanation:
# - Higher ratios = more sampling from that dataset
# - Your custom data has higher ratios (2.0-3.0) for focus
# - Standard datasets have lower ratios (0.5-1.0) for diversity
#
# VITA-Audio-Boost Training:
# - Uses text-audio-interval-ratio: 1 10 4 10
# - Optimized for fast cross-modal token generation
# - Requires proper attention mechanisms and flash attention
#
# Dataset Structure:
# - Each dataset needs proper JSONL format (one JSON per line)
# - Audio paths should be relative to /workspace/VITA-Audio/
# - Messages format: [{"content": "...", "role": "user/assistant"}]
# - Audios format: ["path/to/audio.wav", ...]

